# ğŸ“˜â€¯Guide dÃ©taillÃ© â€“â€¯PrÃ©dictions Ã©tendues pour le projet **Gestion des dÃ©chets hospitaliers**

## ğŸ¯â€¯Objectif du fichier

Ce document dÃ©crit **pas Ã  pas** comment ajouter, entraÃ®ner et Ã©valuer de nouvelles cibles (prÃ©dictions)â€¯:

- `poids_kg` (rÃ©gression)
- `volume_m3` (rÃ©gression)
- `distance_traitement_km` (rÃ©gression)
- `conformite` (classificationâ€¯Oui/Non)
- `incident` (classificationâ€¯Oui/Non)
- `type_conteneur` (classification multiâ€‘classe)
- `entreprise_transport` (classification multiâ€‘classe)

Le processus suit exactement le mÃªme pipeline que le notebook `01_pipeline.ipynb`, mais il est **isolÃ©** dans un script dÃ©diÃ© (`src/extended_predictions.py`) et un notebook supplÃ©mentaire (`notebooks/02_extended_predictions.ipynb`).

---

## ğŸ“‚â€¯Structure du projet (rappel)

```
PROJET_INF_365/
â”‚
â”œâ”€ data/                     # â† CSV source
â”‚   â””â”€ dechets_hospitaliers.csv
â”‚
â”œâ”€ notebooks/
â”‚   â”œâ”€ 01_pipeline.ipynb    # pipeline de base
â”‚   â””â”€ 02_extended_predictions.ipynb   # **nouveau** â€“â€¯prÃ©dictions Ã©tendues
â”‚
â”œâ”€ results/                  # figures & CSV gÃ©nÃ©rÃ©s
â”‚
â”œâ”€ src/
â”‚   â”œâ”€ pipeline_full.py
â”‚   â”œâ”€ extended_predictions.py   # **nouveau** â€“â€¯script complet
â”‚   â””â”€ â€¦ (wrappers)
â”‚
â””â”€ docs/
    â””â”€ extended_predictions.md   # **ce fichier** â€“â€¯guide dÃ©taillÃ©
```

---

## ğŸ› ï¸â€¯Ã‰tapeâ€¯1 â€“â€¯PrÃ©â€‘requis (installations)

```bash
# CrÃ©ez un environnement virtuel (optionnel mais recommandÃ©)
python -m venv venv
source venv/bin/activate   # Linux/macOS
# pip install les dÃ©pendances du projet
pip install -r requirements.txt   # pandas, numpy, scikitâ€‘learn, matplotlib, seaborn, jupyterlab
```

---

## ğŸ““â€¯Ã‰tapeâ€¯2 â€“â€¯Notebook `02_extended_predictions.ipynb`

Le notebook est dÃ©coupÃ© **cellule par cellule**â€¯; chaque cellule comporte une description (Markdown) suivie du code (Python). Vous pouvez simplement ouvrir le fichier dans JupyterLab et exÃ©cuter **Kernel â†’ Restart & Run All**.

### Cellâ€¯1 â€“ Titre & contexte (Markdown)

```markdown
# ğŸ§©â€¯PrÃ©dictions Ã©tendues â€“â€¯Gestion des dÃ©chets hospitaliers

Ce notebook reproduit le pipeline complet du projet, mais se concentre sur les nouvelles cibles listÃ©es ciâ€‘dessus. Toutes les Ã©tapes (import, EDA, prÃ©â€‘traitement, entraÃ®nement, Ã©valuation, visualisation) sont dÃ©taillÃ©es.
```

### Cellâ€¯2 â€“ Imports (Code)

```python
import os, warnings
import numpy as np, pandas as pd
import matplotlib.pyplot as plt, seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import (accuracy_score, classification_report,
                             confusion_matrix, mean_absolute_error,
                             r2_score, roc_auc_score, roc_curve)
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
warnings.filterwarnings('ignore')
%matplotlib inline
sns.set(style='whitegrid')
```

### Cellâ€¯3 â€“ Chemins & dossiers (Code)

```python
DATA_PATH = os.path.join('..', 'data', 'dechets_hospitaliers.csv')
RESULTS_DIR = os.path.join('..', 'results')
os.makedirs(RESULTS_DIR, exist_ok=True)
```

### Cellâ€¯4 â€“ Chargement du CSV (Code)

```python
print('ğŸ” Chargement du jeu de donnÃ©esâ€¦')
df = pd.read_csv(DATA_PATH)
print('Shape :', df.shape)
display(df.head())
```

### Cellâ€¯5 â€“ VÃ©rification des colonnes disponibles (Markdown + Code)

```markdown
## âœ…â€¯VÃ©rification des colonnes

Nous listons les colonnes pour nous assurer que les nouvelles cibles existent.
```

```python
print('Colonnes du DataFrame :')
print(df.columns.tolist())
```

### Cellâ€¯6 â€“ Dictionnaire `TARGETS` Ã©tendu (Code)

```python
TARGETS = {
    # Cibles dÃ©jÃ  prÃ©sentes dans le notebook 01
    'cout'        : 'cout_traitement',
    'type'        : 'type_dechet',
    'risque'      : 'niveau_risque',
    'elimination' : 'mode_elimination',
    # ---------- Nouvelles cibles ----------
    'poids'       : 'poids_kg',                # rÃ©gression
    'volume'      : 'volume_m3',               # rÃ©gression
    'distance'    : 'distance_traitement_km',  # rÃ©gression
    'conformite'  : 'conformite',             # classification (Oui/Non)
    'incident'    : 'incident',               # classification (Oui/Non)
    'conteneur'   : 'type_conteneur',         # classification multiâ€‘classe
    'transport'   : 'entreprise_transport'    # classification multiâ€‘classe
}
```

### Cellâ€¯7 â€“ Fonction utilitaire `prepare_data` (Code)

```python
def prepare_data(target_column: str):
    X = df.drop(columns=[target_column])
    y = df[target_column]
    numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()
    categorical_features = X.select_dtypes(include=['object']).columns.tolist()
    return X, y, numeric_features, categorical_features
```

### Cellâ€¯8 â€“ Transformateurs (Code) â€“ identiques Ã  ceux du notebook 01

```python
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])
```

### Cellâ€¯9 â€“ Fonction `train_and_evaluate` (Code) â€“ **nouvelle version** qui crÃ©e un `ColumnTransformer` local Ã  chaque appel (Ã©vite les conflits)â€¯:

```python
def train_and_evaluate(task: str, target_key: str):
    target_column = TARGETS[target_key]
    X, y, num_cols, cat_cols = prepare_data(target_column)

    # ColumnTransformer local
    preprocess_local = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, num_cols),
            ('cat', categorical_transformer, cat_cols)
        ])

    # Split (stratify si <20 classes)
    stratify = y if (y.nunique() < 20) else None
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=stratify)

    # ModÃ¨le
    if task == 'regression':
        model = RandomForestRegressor(n_estimators=300, random_state=42)
    else:
        model = RandomForestClassifier(n_estimators=300, random_state=42)

    pipe = Pipeline(steps=[('preprocess', preprocess_local), ('model', model)])
    pipe.fit(X_train, y_train)
    y_pred = pipe.predict(X_test)

    metrics = {}
    if task == 'regression':
        metrics['R2']  = r2_score(y_test, y_pred)
        metrics['MAE'] = mean_absolute_error(y_test, y_pred)
    else:
        # Encodage du target si texte
        if y.dtype == 'object':
            le = LabelEncoder()
            y_test_enc = le.fit_transform(y_test)
            y_pred_enc = le.transform(y_pred) if isinstance(y_pred[0], str) else y_pred
            target_names = le.classes_
        else:
            y_test_enc = y_test
            y_pred_enc = y_pred
            target_names = None
        metrics['Accuracy'] = accuracy_score(y_test_enc, y_pred_enc)
        metrics['ClassificationReport'] = classification_report(
            y_test_enc, y_pred_enc, target_names=target_names, output_dict=True)
        # ROC uniquement si binaire
        if len(np.unique(y_test_enc)) == 2:
            y_proba = pipe.predict_proba(X_test)[:, 1]
            fpr, tpr, _ = roc_curve(y_test_enc, y_proba)
            metrics['ROC'] = {'fpr': fpr, 'tpr': tpr,
                               'AUC': roc_auc_score(y_test_enc, y_proba)}
    return pipe, metrics, (X_test, y_test)
```

### Cellâ€¯10 â€“ EntraÃ®nement de **toutes** les nouvelles cibles (Code)

```python
new_keys = ['poids', 'volume', 'distance',
            'conformite', 'incident', 'conteneur', 'transport']

model_results = {}
for key in new_keys:
    task = 'regression' if key in ['poids', 'volume', 'distance'] else 'classification'
    pipe, metrics, data = train_and_evaluate(task, key)
    model_results[key] = {'pipe': pipe, 'metrics': metrics, 'data': data}
    if task == 'regression':
        print(f'ğŸ”¹ {key} (rÃ©gression) â€“ RÂ² = {metrics["R2"]:.4f}, MAE = {metrics["MAE"]:.2f}')
    else:
        print(f'ğŸ”¹ {key} (classification) â€“ Accuracy = {metrics["Accuracy"]:.2%}')
```

### Cellâ€¯11 â€“ Fonctions de visualisation (Code) â€“ mÃªmes que dans le notebook 01

```python
def plot_confusion(cm, classes, title, fname):
    plt.figure(figsize=(6,5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=classes, yticklabels=classes)
    plt.title(title)
    plt.ylabel('Vrai')
    plt.xlabel('PrÃ©dit')
    plt.tight_layout()
    plt.savefig(os.path.join(RESULTS_DIR, fname))
    plt.close()

def plot_roc(fpr, tpr, auc, title, fname):
    plt.figure()
    plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')
    plt.plot([0,1],[0,1],'k--')
    plt.title(title)
    plt.xlabel('FPR')
    plt.ylabel('TPR')
    plt.legend()
    plt.tight_layout()
    plt.savefig(os.path.join(RESULTS_DIR, fname))
    plt.close()
```

### Cellâ€¯12 â€“ Visualisations pour les nouvelles classifications (Code)

```python
classification_keys = ['conformite', 'incident', 'conteneur', 'transport']
for key in classification_keys:
    metrics = model_results[key]['metrics']
    X_test, y_test = model_results[key]['data']
    # DÃ©codage si besoin
    if isinstance(y_test.iloc[0], str):
        le = LabelEncoder()
        y_test_enc = le.fit_transform(y_test)
        y_pred_enc = le.transform(
            model_results[key]['pipe'].predict(X_test))
        class_names = le.classes_
    else:
        y_test_enc = y_test
        y_pred_enc = model_results[key]['pipe'].predict(X_test)
        class_names = np.unique(y_test_enc).astype(str)
    # Confusion
    cm = confusion_matrix(y_test_enc, y_pred_enc)
    plot_confusion(cm, class_names,
                   f'Confusion matrix â€“ {key}', f'confusion_{key}.png')
    # ROC (binaire uniquement)
    if 'ROC' in metrics:
        plot_roc(metrics['ROC']['fpr'], metrics['ROC']['tpr'],
                 metrics['ROC']['AUC'], f'ROC â€“ {key}', f'roc_{key}.png')
```

### Cellâ€¯13 â€“ Tableau rÃ©capitulatif Ã©tendu (Code)

```python
rows = []
for key, info in model_results.items():
    target = TARGETS[key]
    m = info['metrics']
    if 'R2' in m:  # rÃ©gression
        rows.append({'ModÃ¨le': f'{target} (RÃ©gression)',
                     'RÂ²/Accuracy': m['R2'],
                     'MAE': m['MAE']})
    else:          # classification
        rows.append({'ModÃ¨le': f'{target} (Classification)',
                     'RÂ²/Accuracy': m['Accuracy'],
                     'MAE': np.nan})
summary_ext = pd.DataFrame(rows)
display(summary_ext)
# Sauvegarde CSV
summary_path = os.path.join(RESULTS_DIR, 'summary_extended.csv')
summary_ext.to_csv(summary_path, index=False)
print(f'ğŸ“ Tableau rÃ©capitulatif sauvegardÃ© â†’ {summary_path}')
```

### Cellâ€¯14 â€“ SÃ©lection du meilleur modÃ¨le (Code)

```python
best_reg = max(
    [(r['ModÃ¨le'], r['RÂ²/Accuracy']) for _, r in summary_ext.iterrows()
    if 'RÃ©gression' in r['ModÃ¨le']],
    key=lambda x: x[1])
best_clf = max(
    [(r['ModÃ¨le'], r['RÂ²/Accuracy']) for _, r in summary_ext.iterrows()
    if 'Classification' in r['ModÃ¨le']],
    key=lambda x: x[1])
print(f'ğŸ” Meilleur modÃ¨le **rÃ©gression** â†’ {best_reg[0]} (RÂ² = {best_reg[1]:.4f})')
print(f'ğŸ” Meilleur modÃ¨le **classification** â†’ {best_clf[0]} (Accuracy = {best_clf[1]:.2%})')
```

---

## ğŸ–¥ï¸â€¯Ã‰tapeâ€¯3 â€“â€¯Script Python autonome (`src/extended_predictions.py`)

Le script reproduit exactement le notebook ciâ€‘dessus, mais il peut Ãªtre exÃ©cutÃ© depuis le terminalâ€¯:

```bash
python src/extended_predictions.py
```

Il crÃ©e les mÃªmes figures dans `results/` et le fichier CSV `summary_extended.csv`.

---

## ğŸ“¦â€¯Ã‰tapeâ€¯4 â€“â€¯ExÃ©cution & vÃ©rification

1. **Lancez le notebook** `02_extended_predictions.ipynb` et assurezâ€‘vous que toutes les cellules sâ€™exÃ©cutent sans erreur.
2. **VÃ©rifiez le dossier `results/`**â€¯: vous y trouverez les matrices de confusion, les courbes ROC (pour les variables binaires) et le barâ€‘plot global.
3. **Ouvrez `results/summary_extended.csv`** pour comparer les scores de chaque modÃ¨le.
4. **Utilisez le script** `src/extended_predictions.py` si vous prÃ©fÃ©rez une exÃ©cution en ligne de commande.

---

## ğŸš€â€¯Prochaines amÃ©liorations possibles

- **Hyperâ€‘parameter tuning** avec `GridSearchCV` ou `RandomizedSearchCV` pour chaque modÃ¨le.
- **Essayer dâ€™autres algorithmes**â€¯: XGBoost, LightGBM, CatBoost (surtout pour les variables catÃ©gorielles).
- **Feature engineering**â€¯: crÃ©er des interactions (ex.â€¯`poids * distance`) ou des variables dÃ©rivÃ©es (`jour_semaine` Ã  partir de `date_collecte`).
- **Enregistrement des modÃ¨les** (`joblib.dump(pipe, 'model_<cible>.pkl')`) pour les rÃ©â€‘utiliser dans une API ou un tableau de bord.

---

## ğŸ“šâ€¯Conclusion

Ce guide vous fournit **tout le nÃ©cessaire** pour ajouter, entraÃ®ner et Ã©valuer de nouvelles prÃ©dictions dans le projet de gestion des dÃ©chets hospitaliers, Ã  la fois sous forme de **notebook** dÃ©taillÃ© et de **script Python** autonome. Vous pouvez maintenant explorer davantage les relations entre les variables et enrichir votre analyse avec les mÃ©triques les plus pertinentes.

_Bon codageâ€¯!_ ğŸ‰
